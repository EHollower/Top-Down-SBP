# Top-Down-SBP

Analysis and implementation of Top-Down Stochastic Block Partitioning (HPDC '25). Scaling graph clustering by replacing bottom-up merges with block-splitting to achieve 7.7x speedup and 4.1x memory efficiency. 

**Paper**: https://dl.acm.org/doi/pdf/10.1145/3731545.3731589

## Quick Start

### Build & Run Demo
```bash
./build.sh release run
```

### Run Full Benchmark Suite
```bash
./build.sh              # Compile both executables
./bin/sbp_benchmark     # Run benchmark (5-10 minutes)
./scripts/analyze_results.sh  # Analyze results
```

## Executables

The build script generates two binaries:

1. **`bin/sbp_experiment`** - Single demonstration run
   - Quick test on synthetic SBM graph
   - Shows clustering quality and runtime
   - Good for testing algorithm changes

2. **`bin/sbp_benchmark`** - Full benchmark suite
   - Tests 3 graph sizes: 200, 400, 800 vertices
   - 5 runs per configuration for statistical reliability
   - Compares Top-Down vs. Bottom-Up performance
   - Outputs CSV with detailed metrics
   - Runtime: ~5-10 minutes

## Running Benchmarks

### Execute Benchmark
```bash
./bin/sbp_benchmark
```

**What it does:**
- Generates Stochastic Block Model (SBM) graphs with ground truth labels
- Tests both Top-Down and Bottom-Up algorithms
- Performs 5 runs per graph configuration for robustness
- Measures: runtime, memory (RSS), NMI accuracy, MDL quality
- Saves results to `results/benchmark_results.csv`

**Graph configurations** (can be modified in `src/benchmark_sbp.cpp:135`):
- Small: 200 vertices, 5 clusters
- Medium: 400 vertices, 7 clusters
- Large: 800 vertices, 9 clusters

### Analyze Results
```bash
./scripts/analyze_results.sh
```

**Output includes:**
- Average runtime by algorithm
- Average NMI (clustering accuracy)
- Average memory usage
- Performance breakdown by graph size
- Speedup comparison (Top-Down vs. Bottom-Up)

### CSV Format
`results/benchmark_results.csv` contains:
- `graph_id` - Graph configuration (0=200v, 1=400v, 2=800v)
- `num_vertices` - Graph size
- `num_edges` - Edge count
- `target_clusters` - Number of clusters K
- `algorithm` - TopDown or BottomUp
- `run_number` - Run index (0-4)
- `runtime_sec` - Wall-clock time in seconds
- `memory_mb` - Peak RSS memory in MB
- `nmi` - Normalized Mutual Information (0-1, higher = better)
- `mdl_raw` - Raw MDL score
- `mdl_norm` - Normalized MDL (H/H_null)
- `clusters_found` - Final number of clusters detected

## Development Workflow (nvim + tmux)

### Option 1: Automated tmux session
```bash
./dev.sh
```

Creates a 3-pane tmux layout:
- **Left**: Neovim editor
- **Top-right**: Build commands
- **Bottom-right**: Program output

### Option 2: Manual tmux setup
```bash
tmux new -s sbp
# Ctrl+b " (split horizontal)
# Ctrl+b % (split vertical in right pane)

# Left pane: nvim src/main_sbp.cpp
# Top-right: ./build.sh release
# Bottom-right: ./bin/sbp_experiment
```

## Build Options
```bash
./build.sh debug          # Debug build with symbols (for development)
./build.sh release        # Optimized release build (for benchmarks)
./build.sh release run    # Build and run demo immediately
```

**Note**: Always use release mode for benchmarks to get accurate performance measurements.

## Project Structure
```
src/
├── sbp_utils.hpp       # Core: Graph, Blockmodel, MDL calculation
├── top_down_sbp.cpp    # Top-Down SBP (divisive clustering)
├── bottom_up_sbp.cpp   # Bottom-Up SBP (agglomerative)
├── main_sbp.cpp        # Demo: single experiment
└── benchmark_sbp.cpp   # Benchmark harness: full suite

scripts/
└── analyze_results.sh  # CSV analysis (awk/bash, no dependencies)

results/
└── benchmark_results.csv  # Generated by sbp_benchmark (gitignored)
```

## Algorithms

### Top-Down SBP
- **Strategy**: Divisive (starts with 1 cluster, splits iteratively)
- **Heuristic**: Connectivity Snowball with random seeds
- **Advantage**: Lower memory footprint, faster early iterations
- **Parallelization**: OpenMP in split candidate generation

### Bottom-Up SBP
- **Strategy**: Agglomerative (starts with V clusters, merges)
- **Challenge**: "Front-loading" problem (high initial overhead)
- **Advantage**: Often achieves higher clustering accuracy (NMI)

## Metrics Explained

- **MDL (Minimum Description Length)**: Objective function (lower = better compression = better clustering)
- **NMI (Normalized Mutual Information)**: Cluster quality vs. ground truth (0-1, 1.0 = perfect)
- **Runtime**: Wall-clock time with OpenMP parallelization
- **Memory**: Peak RSS (Resident Set Size) in MB

## Typical Benchmark Results

From a sample run on AMD Ryzen 9 7845HX:

```
=== Speedup: Top-Down vs. Bottom-Up ===
N    | Top-Down (s) | Bottom-Up (s) | Speedup
 200 |       0.032  |        0.987  |   30.5x
 400 |       0.050  |        9.484  |  189.9x
 800 |       0.072  |       88.719  | 1228.3x
```

**Key observations:**
- Top-Down is 30-1200× faster (speedup increases with graph size)
- Bottom-Up achieves higher NMI (~97.5% vs ~24.5%)
- Clear speed/accuracy tradeoff demonstrated

## Neovim LSP (clangd)
Configured in `.clangd`:
- Autocomplete: Works automatically
- Jump to definition: `gd`
- Find references: `gr`
- Hover documentation: `K`

**Note**: clangd may show false errors for OpenMP and some STL features. If code compiles with `./build.sh`, ignore LSP warnings.

## Verifying Correctness
The implementation uses synthetic SBM graphs with ground truth labels. 
Check **NMI scores** in output to verify clustering quality:
- NMI > 0.9: Excellent clustering
- NMI 0.7-0.9: Good clustering
- NMI < 0.5: Poor clustering

## Requirements
- **Compiler**: g++-14 or later (C++20 support)
- **Libraries**: OpenMP (usually bundled with gcc)
- **OS**: Linux (tested on Ubuntu/Debian)
- **Memory**: ~1GB for benchmark suite

## Troubleshooting

**Benchmark crashes or hangs:**
- Ensure you're using release mode: `./build.sh release`
- Check available memory: `free -h` (need ~1GB free)
- Reduce graph sizes in `src/benchmark_sbp.cpp` if needed

**Compilation errors:**
- Verify g++-14 is installed: `g++-14 --version`
- Install OpenMP: `sudo apt install libomp-dev` (if missing)

**Low NMI scores:**
- This is expected for Top-Down with default parameters
- Adjust MCMC iterations in `src/top_down_sbp.cpp:161` for better accuracy
- Bottom-Up typically achieves higher NMI but slower runtime

## Citation
```bibtex
@inproceedings{ammar2025topdown,
  title={Top-Down Stochastic Block Partitioning: Turning Graph Clustering Upside Down},
  author={Ammar, Omar and Wolfe, Cameron and Chaudhari, Pratik},
  booktitle={Proceedings of the 34th International Symposium on High-Performance Parallel and Distributed Computing},
  year={2025}
}
```
